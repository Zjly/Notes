

# Causal Intervention for Leveraging Popularity Bias in Recommendation

### 研究背景

推荐系统中存在着一种流行度偏差问题，即热门的物品会更容易受到系统的推荐，在推荐结果上呈现一种长尾分布。但是，并不是所有的偏差都是有害的，有一些物品由于某些原因获得了更高的受欢迎程度，若是过于的追求降低偏差，会降低推荐的准确性和用户的满意程度。

现有的基于流行度偏差而进行推荐的方法主要有如下几个：

- *Inverse Propensity Scoring*通过对模型训练中的交互示例进行重新加权操作，使数据分布趋向于均匀。但是它在估计模型的倾向性和方差方面较为困难。
- *Cuasal Embedding*通过无偏的均匀数据指导模型学习无偏嵌入，但是获取这种数据需要随机地向用户推荐物品以获取行为记录，有可能使用户的体验变差且数据量较小。
- *Ranking Adjustment*对推荐结果进行重排或是在训练时执行模型正则化，但是两种方法缺乏有效的理论基础。

某些流行的物品由于其内在因素而受到了欢迎，继续推荐它应该是有利的，而一味地消除流行度偏差会丢失数据中的一些信息，论文研究了如何利用流行度偏差来提升推荐的准确性。

### 因果图

![image-20210604191546929](https://raw.githubusercontent.com/Zjly/Image-hosting/master/image-20210604191546929.png)

因果图能够表示物品流行性对推荐过程的影响，传统的方法主要基于user-item匹配来计算推荐得分，U与I是原因，而C表示了U与I之间的交互概率，这种粗粒度的建模方法并没有明确地考虑到物品的流行度。

- U代表用户节点，例如可以代表用户的个人资料或是历史特征
- I代表被推荐的物品节点，论文中假设用户只能与被推荐给它的物品进行交互
- C代表交互标签，表示用户是否与被推荐的物品进行了交互
- Z代表着物品的流行度
- 边$\{U,I,Z\}\to C$代表交互标签C由U，I和Z三个因素所共同决定。传统方法仅考虑到了$\{U,I\}\to C$，即用户的兴趣和物品的匹配决定了用户是否会与该物品交互。而论文中加入了Z来捕获用户的从众心理，即用户会倾向于大多数人的选择，去与热门的物品进行交互
- 边$Z \to I$代表物品的流行度会影响到物品的被推荐的程度，也就是说数据的偏差会影响到推荐系统并使推荐系统更频繁的去推荐这些流行度高的物品。也就是说，边$Z \to I$会对推荐的结果造成不良的影响，需要在制定预测模型的时候被剔除。

因果图能够表示物品流行性对推荐过程的影响：

- 传统的方法主要基于user-item匹配来计算推荐得分，U与I是原因，而C表示了U与I之间的交互概率，这种粗粒度的建模方法并没有明确地考虑到物品的流行度。
- Z有两条边指向I与C：
  - $Z\to C$代表着物品流行度会直接影响交互概率，因为许多用户由于从众心理会跟随大多数人去选择流行度更高的物品。
  - $Z\to I$代表着物品的流行度会影响物品被推荐的概率，因为数据的偏差会影响到推荐系统并使推荐系统更频繁的去推荐这些流行度高的物品。
  - 流行度Z会通过两个因果路径影响到交互概率C：
    - $Z\to C$
    - $Z\to I\to C$ 其增加了重复的物品交互信息，放大了流行度的偏差


### 先导知识

$\mathcal{D}$由t个阶段的历史数据所构成，即$\mathcal{D}=\{\mathcal{D_1}\cup...\cup\mathcal{D_T}\}$。同理，$\mathcal{U}=\{\mathcal{u_1}\cup...\cup\mathcal{u_{|u|}\}}$代表所有的用户，$\mathcal{I}=\{\mathcal{i_1}\cup...\cup\mathcal{i_{|I|}\}}$代表所有的物品。

推荐系统会根据历史数据，从中学习用户的偏好，在未来也就是$\mathcal{D_{T+1}}$上提高推荐的精度。论文将阶段$t$上的物品的局部流行度（local popularity）定义为公式1的形式：

$m^i_t=D^t_i/\sum_\limits{j\in I}D^t_j \tag{1}$

其中，$D^t_i$表示在阶段$\mathcal{D_T}$中物品$i$的交互次数。类似的，可以在$\mathcal{D}$中定义一个基于物品$m_i$交互频率的全局流行度，但是，论文中认为局部流行度对于系统的推荐机制和用户角色的影响更大，因为系统会定期重新训练，并且最近的数据的影响最大。

事实上，物品的流行度是会随着时间而变化的，所以流行度偏差也会随着时间的改变而改变。因此，论文定义了一个名为*Drift of Popularity*（DP，流行度漂移）的度量去度量两种阶段之间的偏移。将阶段中每个物品的概率表示为$m^t_{|I|}$，在t阶段中所有物品的规律分布为$[m^t_1,...,m^t_{|I|}]$。然后使用Jensen-Shannon Divergence（JSD）来测量两个阶段之间的相似度，其范围在$[0,\log(2)]$之间，数值越大表示流行度漂移越大，其数学表示如公式2所示：

$DP(t,s)=JSD([m^t_1,...,m^t_{|I|}],[m^s_1,...,m^s_{|I|}]) \tag{2}$

![image-20210607140542918](https://raw.githubusercontent.com/Zjly/Image-hosting/master/image-20210607140542918.png)

左图是阶段t和t+1之间的流行度漂移的可视图，可以看出流行度漂移在三个数据集中都有存在，不同数据集中的流行度漂移的值不相同；右图是阶段1和t之间的流行度漂移的可视图，衡量了流行度漂移的累积值，可以看出流行度漂移的值会随着时间间隔的增长而增加。

### Deconfounded Training

更改训练所用的数据集是去除$Z\to I$也就是物品的流行度对物品推荐概率的影响的方法之一：通过随机向用户推荐物品来获得用户与物品之间的交互数据，可以使其不受到$Z\to I$的影响。但是，这种方法只能由预构建者来干预且对用户的影响较大，所以使用的效果并不是非常好。

论文基于因果科学，使用do演算切断了$Z\to I$的路径。使用$P(C|do(U,I))$来消除$P(C|U,I)$中混淆的用户兴趣和流行度偏见。图1.b中的因果图为$G$，图1.c中的因果图为$G'$，对$G$执行do演算，其数学表示如公式3所示：

$\begin{equation} \begin{aligned} P(C|do(U,I))&\overset{(1)}{=}P_{G'}(C|U,I) \\&\overset{(2)}{=}\underset{z}{\sum}P_{G'}(C|U,I,z)P_{G'}(z|U,I) \\&\overset{(3)}{=}\underset{z}{\sum}P_{G'}(C|U,I,z)P_{G'}(z) \\&\overset{(4)}{=}\underset{z}{\sum}P_{G'}(C|U,I,z)P(z) \end{aligned} \end{equation} \tag{3}$

其中$P_{G'}$表示在$G'$上评估的概率函数，其推导过程如下：

- (1)因为*backdoor criterion*，作为$G$中的唯一的后门路径$I\gets Z \to C$被$do(U,I)$所阻塞
- (2)因为Bayes’ theorem
- (3)因为U和I与$G'$中的$z$是独立的
- (4)$P(C|U,I,Z)=P_{G'}(C|U,I,Z)$ 是因为在切断$Z\to I$时不会改变${U,I,Z}\to C$的因果机制，而$P(Z)=P_{G'}(Z)$是因为他们有共同的祖先。

